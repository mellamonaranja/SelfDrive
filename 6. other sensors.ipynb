{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fb53cb-dc37-4b4f-8abc-2265e9c7a921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import carla \n",
    "import math \n",
    "import random \n",
    "import time \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Connect the client and set up bp library and spawn points\n",
    "client = carla.Client('localhost', 2000) \n",
    "world = client.get_world()\n",
    "bp_lib = world.get_blueprint_library() \n",
    "spawn_points = world.get_map().get_spawn_points() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dde5d2-c93b-4763-b52f-02de50a28926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the ego vehicle\n",
    "vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020') \n",
    "vehicle = world.try_spawn_actor(vehicle_bp, spawn_points[79])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2e271a-3918-449f-a0fe-0b4460d95df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Move the spectator behind the vehicle to view it\n",
    "spectator = world.get_spectator() \n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=2.5)),vehicle.get_transform().rotation) \n",
    "spectator.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc482f78-904b-4b31-9cda-88688e7410d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add traffic\n",
    "for i in range(300): \n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle')) \n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d153266-72c9-4765-bd73-b6869617c05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set traffic in motion\n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.set_autopilot(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be506723-e2d0-4be4-9a77-29fbaafe6559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add camera sensor\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb') \n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Add navigation sensor\n",
    "gnss_bp = bp_lib.find('sensor.other.gnss')\n",
    "gnss_sensor = world.spawn_actor(gnss_bp, carla.Transform(), attach_to=vehicle)\n",
    "\n",
    "# Add inertial measurement sensor\n",
    "imu_bp = bp_lib.find('sensor.other.imu')\n",
    "imu_sensor = world.spawn_actor(imu_bp, carla.Transform(), attach_to=vehicle)\n",
    "\n",
    "# Add collision sensor\n",
    "collision_bp = bp_lib.find('sensor.other.collision')\n",
    "collision_sensor = world.spawn_actor(collision_bp, carla.Transform(), attach_to=vehicle)\n",
    "\n",
    "# Add lane invasion sensor\n",
    "lane_inv_bp = bp_lib.find('sensor.other.lane_invasion')\n",
    "lane_inv_sensor = world.spawn_actor(lane_inv_bp, carla.Transform(), attach_to=vehicle)\n",
    "\n",
    "# Add obstacle detector\n",
    "obstacle_bp = bp_lib.find('sensor.other.obstacle')\n",
    "obstacle_bp.set_attribute('hit_radius','0.5')\n",
    "obstacle_bp.set_attribute('distance','50')\n",
    "obstacle_sensor = world.spawn_actor(obstacle_bp, carla.Transform(), attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0429d0c-d0e5-4b4f-b887-ec62fc2178b4",
   "metadata": {},
   "source": [
    "# get_inverse_matrix(self)\n",
    "    Computes the 4-matrix representation of the inverse transformation.\n",
    "    \n",
    "# opencv.circle(image, center_coordinates, radius, color, thickness)\n",
    "     is used to draw a circle on any image.\n",
    "     center_coordinates: It is the center coordinates of the circle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7738402c-38b3-41f0-82b0-bf885e7299e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#why rgb has np, others have list, dict...\n",
    "def rgb_callback(image, data_dict):\n",
    "    data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "def gnss_callback(data, data_dict):\n",
    "    data_dict['gnss'] = [data.latitude, data.longitude]\n",
    "\n",
    "def imu_callback(data, data_dict):\n",
    "    data_dict['imu'] = {\n",
    "        'gyro': data.gyroscope,\n",
    "        'accel': data.accelerometer,\n",
    "        'compass': data.compass\n",
    "    }\n",
    "    \n",
    "def lane_inv_callback(event, data_dict): #when the car crosses into another lane, it using a boolean flag, we  detect flag->put an alert\n",
    "    data_dict['lane_invasion'] == True\n",
    "    \n",
    "def collision_callback(event, data_dict):\n",
    "    data_dict['collision'] = True\n",
    "    \n",
    "def obstacle_callback(event, data_dict, camera, k_mat):\n",
    "    #It uses a cone in front of the vehicle to detect if there are upcoming obstacles\n",
    "    #whenever an obstacle is detected, we can get the transform(type id)\n",
    "    \n",
    "    if 'static' not in event.other_actor.type_id:\n",
    "        #detect is 'static' like a road or things on the sidewalk\n",
    "        data_dict['obstacle'].append({'transform': event.other_actor.type_id, 'frame': event.frame})\n",
    "        \n",
    "    world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "    # print('world_2_camera : ',world_2_camera[0])\n",
    "    \n",
    "    image_point = get_image_point(event.other_actor.get_transform().location, k_mat, world_2_camera)\n",
    "    # print('image_point shape : ', image_point.shape)\n",
    "    # print('image_point : ', image_point[0])\n",
    "    # print('image_point : ', image_point[1])\n",
    "    \n",
    "    if  0 < image_point[0] < image_w and 0 < image_point[1] < image_h:\n",
    "        cv2.circle(data_dict['rgb_image'], tuple(image_point), 10, (0,0,255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ca619e-bdcd-4624-ad36-d57ea52d9a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# project things from the simulation into the camera image\n",
    "# Auxilliary geometry functions for transforming to screen coordinates\n",
    "\n",
    "def build_projection_matrix(w, h, fov):#Horizontal field of view of the image.\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "    K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K\n",
    "\n",
    "def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate: why change?\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x): why?? the order??\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix-->the result is 2d...\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2] #hm...why devide by -z\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return tuple(map(int, point_img[0:2]))\n",
    "    \n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float()\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K = build_projection_matrix(image_w, image_h, fov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "474508fb-6f01-472d-b06f-01d514e9d829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise data\n",
    "collision_counter = 20\n",
    "lane_invasion_counter = 20\n",
    "sensor_data = {\n",
    "    'rgb_image': np.zeros((image_h, image_w, 4)),\n",
    "               'collision': False,\n",
    "               'lane_invasion': False,\n",
    "               'gnss': [0,0],\n",
    "               'obstacle': [],\n",
    "               'imu': {\n",
    "                    'gyro': carla.Vector3D(),\n",
    "                    'accel': carla.Vector3D(),\n",
    "                    'compass': 0 #hm, different type...?\n",
    "                }}\n",
    "\n",
    "# OpenCV window with initial data\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('RGB Camera', sensor_data['rgb_image'])\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# Start sensors recording data\n",
    "camera.listen(lambda image: rgb_callback(image, sensor_data))\n",
    "collision_sensor.listen(lambda event: collision_callback(event, sensor_data))\n",
    "gnss_sensor.listen(lambda event: gnss_callback(event, sensor_data))\n",
    "imu_sensor.listen(lambda event: imu_callback(event, sensor_data))\n",
    "lane_inv_sensor.listen(lambda event: lane_inv_callback(event, sensor_data))\n",
    "obstacle_sensor.listen(lambda event: obstacle_callback(event, sensor_data, camera, K))\n",
    "\n",
    "# Some parameters for text on screen\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,50)\n",
    "fontScale              = 0.5\n",
    "fontColor              = (255,255,255)\n",
    "thickness              = 2\n",
    "lineType               = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9d472-73bd-4b57-8106-3ae0fcd787f4",
   "metadata": {},
   "source": [
    "# cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]]) : put the text on the image or video\n",
    "\n",
    "    org: It is the coordinates of the bottom-left corner of the text string in the image. The coordinates are represented as tuples of two values\n",
    "    \n",
    "# cv2.line(image, start_point, end_point, color, thickness) : draw a line on any image\n",
    "    cv2.line(image, start_point, end_point, color, thickness) \n",
    "    \n",
    "    start_point: It is the starting coordinates of the line. The coordinates are represented as tuples of two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e136318-1832-4c3a-9583-70465cf196b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the compass data (in radians) as a line with cardinal directions as capitals\n",
    "def draw_compass(img, theta):\n",
    "    \n",
    "    compass_center = (700, 100)\n",
    "    compass_size = 50\n",
    "    \n",
    "    cardinal_directions = [\n",
    "        ('N', [0,-1]),\n",
    "        ('E', [1,0]),\n",
    "        ('S', [0,1]),\n",
    "        ('W', [-1,0])\n",
    "    ]#strange coordinate\n",
    "    \n",
    "    for car_dir in cardinal_directions:\n",
    "        cv2.putText(sensor_data['rgb_image'], car_dir[0], \n",
    "        (int(compass_center[0] + 1.2 * compass_size * car_dir[1][0]), int(compass_center[1] + 1.2 * compass_size * car_dir[1][1])), \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        thickness,\n",
    "        lineType)\n",
    "    \n",
    "    compass_point = (int(compass_center[0] + compass_size * math.sin(theta)), int(compass_center[1] - compass_size * math.cos(theta)))\n",
    "    cv2.line(img, compass_center, compass_point, (255, 255, 255), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70470c-b9ce-4bab-9a65-5c7fe0d11fe1",
   "metadata": {},
   "source": [
    "# carla.Vector3D :\n",
    "    Helper class to perform 3D operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fedaf30-d201-45b8-b526-c6c40c894401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Indefinite loop \n",
    "while True:\n",
    "    \n",
    "    # Latitude from GNSS sensor\n",
    "    cv2.putText(sensor_data['rgb_image'], 'Lat: ' + str(sensor_data['gnss'][0]), \n",
    "    (10,30), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    thickness,\n",
    "    lineType)\n",
    "    \n",
    "    # Longitude from GNSS sensor\n",
    "    cv2.putText(sensor_data['rgb_image'], 'Long: ' + str(sensor_data['gnss'][1]), \n",
    "    (10,50), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    thickness,\n",
    "    lineType)\n",
    "    \n",
    "    # Calculate acceleration vector minus gravity\n",
    "    accel = sensor_data['imu']['accel'] - carla.Vector3D(x=0,y=0,z=9.81)\n",
    "    \n",
    "    # Display acceleration magnitude\n",
    "    cv2.putText(sensor_data['rgb_image'], 'Accel: ' + str(accel.length()), \n",
    "    (10,70), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    thickness,\n",
    "    lineType)\n",
    "    \n",
    "    # Gyroscope output\n",
    "    cv2.putText(sensor_data['rgb_image'], 'Gyro: ' + str(sensor_data['imu']['gyro'].length()), \n",
    "    (10,100), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    thickness,\n",
    "    lineType)\n",
    "    \n",
    "    # Compass value in radians, North is 0 radians\n",
    "    cv2.putText(sensor_data['rgb_image'], 'Compass: ' + str(sensor_data['imu']['compass']), \n",
    "    (10,120), \n",
    "    font, \n",
    "    fontScale,\n",
    "    fontColor,\n",
    "    thickness,\n",
    "    lineType)\n",
    "    \n",
    "    # Draw the compass\n",
    "    draw_compass(sensor_data['rgb_image'], sensor_data['imu']['compass'])\n",
    "    \n",
    "    # Print 'COLLISION' to screen when flag is True\n",
    "    # persist for 20 frames\n",
    "    if sensor_data['collision']:\n",
    "        collision_counter -= 1\n",
    "        if collision_counter <= 1:\n",
    "            sensor_data['collision'] = False\n",
    "        cv2.putText(sensor_data['rgb_image'], 'COLLISION', \n",
    "        (250, 300), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        2,\n",
    "        (255,255,255),\n",
    "        3,\n",
    "        2)\n",
    "    else:\n",
    "        collision_counter = 20\n",
    "        \n",
    "    # Print 'LANE INVASION' to screen when flag is True\n",
    "    # persist for 20 frames\n",
    "    if sensor_data['lane_invasion']:\n",
    "        lane_invasion_counter -= 1\n",
    "        if lane_invasion_counter <= 1:\n",
    "            sensor_data['lane_invasion'] = False\n",
    "        cv2.putText(sensor_data['rgb_image'], 'LANE INVASION', \n",
    "        (190, 350), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        2,\n",
    "        (255,255,255),\n",
    "        3,\n",
    "        2)\n",
    "    else:\n",
    "        lane_invasion_counter = 20\n",
    "     \n",
    "    # Display RGB image with imshow\n",
    "    cv2.imshow('RGB Camera', sensor_data['rgb_image'])\n",
    "    \n",
    "    # Break the loop if the user presses the Q key\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386aef1f-52f3-4a78-a401-5ecf016f7886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close the OpenCV display window when the game loop stops and stop sensors\n",
    "camera.stop()\n",
    "collision_sensor.stop()\n",
    "gnss_sensor.stop()\n",
    "imu_sensor.stop()\n",
    "lane_inv_sensor.stop()\n",
    "obstacle_sensor.stop()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "127c1a13-7660-4f28-8935-1534b5ab6823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\workspace\\\\carla\\\\carla\\\\exercise'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62093177-2b96-467c-ab6f-24091136d2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
